
## üë• **√âQUIPE DU PROJET**

**NOUBISSI FOPA CHRISTIAN JUNIOR**  
- **ESSUTHI MBANGUE ANGE ARMEL**  
- **NGUEMTCHUENG TSAMO BIBIANE DANIELLE**  
- **MOUKEKI INDJANDJA DAVE KEVIN**  
- **ABANDA ARMAND WILFRIED**  

**SUPERVISION : PR. PAULIN MALETAGIA**

## üë§ Contribution ‚Äì ESSUTHI MBANGUE ANGE ARMEL

Dans ce projet de reconnaissance automatique de la parole en langue Yemba, j‚Äôai particip√© activement aux t√¢ches suivantes :

- Analyse et pr√©paration des donn√©es audio
- Contribution au d√©veloppement du mod√®le RNN Seq2Seq avec m√©canisme d‚Äôattention
- Tests du syst√®me et analyse des performances
- Corrections et am√©liorations du code
- Contr√¥le de la qualit√© globale de l‚Äôimpl√©mentation

üîó D√©p√¥t original :  
https://github.com/NFChristianJ/RNN-pour-ASR-en-Yemba


#  Reconnaissance Automatique de la Parole en Yemba (ASR-Yemba)


Ce projet propose une **application de reconnaissance vocale automatique (ASR)** pour la langue **Yemba**, une langue tonale du Cameroun. Il s‚Äôappuie sur une architecture **GRU Seq2Seq avec m√©canisme d‚Äôattention additive**, permettant la transcription syllabique et tonale √† partir d‚Äô√©chantillons audio.

##  Objectif du projet

D√©velopper un mod√®le capable de transcrire automatiquement les √©nonc√©s oraux en Yemba en int√©grant :
- La **structure syllabique**
- Les **variations tonales (haut, moyen, bas)**
- Un **vocabulaire personnalis√©** issu du corpus *YembaTones*

---

##  Donn√©es utilis√©es

Le projet utilise le corpus [YembaTones](https://data.mendeley.com/datasets/cx268tmrwn/3) :
- 344 mots en Yemba, enregistr√©s par 11 locuteurs natifs.
- Fichiers `.wav` + annotations `.TextGrid` (segmentations syllabiques et tons).
- Format unifi√© de transcription : `syllabe|ton syllabe|ton ...`


##  Architecture du mod√®le

L‚Äôarchitecture impl√©ment√©e se compose de :

| Module        | Description |
|---------------|-------------|
| `GRUEncoder`  | GRU bidirectionnel pour encoder les melspectrogrammes. |
| `Attention`   | M√©canisme de Bahdanau pour le focus dynamique. |
| `GRUDecoder`  | GRU unidirectionnel pour g√©n√©rer la transcription. |
| `GRUSeq2Seq`  | Int√©gration compl√®te de l‚Äôencodeur, attention et d√©codeur. |

Le mod√®le final est d√©fini dans [`model.py`](./model.py). Plusieurs variantes sont incluses : BiLSTM-CTC, BiGRU-CTC, CNN-BiLSTM, etc.

---

##  Pipeline de traitement

1. **Pr√©traitement audio** (Mono 16kHz) ‚Üí extraction des **Melspectrogrammes**.
2. **Tokenisation** des transcriptions syllabico-tonales.
3. **Division du jeu de donn√©es** (80% train / 10% val / 10% test).
4. **Entra√Ænement** avec `CrossEntropyLoss`, `Teacher Forcing`, et `EarlyStopping`.
5. **√âvaluation** avec les m√©triques :
   - WER (Word Error Rate)
   - CER (Character Error Rate)
   - Pr√©cision brute
6. **D√©ploiement** via interface [Gradio](https://www.gradio.app).

---

## üíª Interface Utilisateur

Une application web simple construite avec **Gradio** permet :
- Chargement d‚Äôun fichier `.wav`
- Transcription brute avec les tons (`paÃÅ|haut`)
- Transcription nettoy√©e pour la lecture (`paÃÅ`)

‚û°Ô∏è [Acc√®s temporaire en ligne](https://fc228289ee29034f60.gradio.live/)

---

##  R√©sultats

| Indicateur | Valeur |
|------------|--------|
| **WER**    | 63.02% |
| **CER**    | 42.79% |
| **Pr√©cision brute** | ~8.63% |

---

##  D√©pendances principales

```bash
torch >= 2.x
torchaudio
numpy, pandas
matplotlib
gradio
jiwer
soundfile
````

 V√©rifiez [`test.py`](./test.py) pour les formats audio support√©s via `soundfile`.

---

## Consid√©rations √©thiques

* Respect des donn√©es personnelles : pas de collecte utilisateur.
* Corpus anonymis√© et ouvert (licence acad√©mique).
* Code source transparent et reproductible.
* Biais reconnus et d√©crits (√¢ge, zone g√©ographique, style de parole).
* Finalit√© strictement √©ducative, patrimoniale et scientifique.

---

##  Lancer l'application en local

```bash
# Installation
pip install -r requirements.txt

# Ex√©cution locale
python interface.py  # ou autre script Gradio d'interface
```

---

##  R√©f√©rences cl√©s

* [YembaTones Corpus](https://data.mendeley.com/datasets/cx268tmrwn/3)
* [PyTorch](https://pytorch.org)
* [Gradio](https://www.gradio.app/)
* [Hugging Face ASR Models](https://huggingface.co/models?pipeline_tag=automatic-speech-recognition)
* [DeepSpeech Mandarin](https://github.com/PaddlePaddle/DeepSpeech)

```

